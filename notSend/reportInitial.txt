grass growth function, farmer sheep
custom neural network, x100 as fast. Our implementation is very basic, but can be trained way quicker, overcoming previous keras model
list all parameters
list breeding counts over learning
testing if network can have specified shape
think about adding dropout
there was a huge problem with dead neurons, so relu was swapped for leaky relu
changed the way the output works: initially, the model could pick any position within it's range as a different output neuron.
    This meant that moving 4 tiles up and 5 tiles up were completely different  decisions
    Now, the output consists of 3 neurons, 2 representing the angle and 1 representing the distance
    2 neurons have to


changed the way the input works:
    initially, the model received 13 values:
        - 3 proximity values for every type of organism (proximity was our own arbitrary function for determing the density of other entities in the area)
        - 3*2 coordinates for nearest instance of every organism type
        - 2 controlled entity own coordinates
        - self.hp
        - self.food

    now, the model receives:
        - an cnn-like image of the square with side length 5 times the controlled entity's speed
        - self.hp
        - self.food
        - maybe some random number?


    outlook intentionally uses the manhatan distance. Later, we may be able to see some interesting differences in the corner of the outlook.
    (My prediciton is that it will ignore them a bit more than the rest)



enviroment details:
    multiple sheep can defeat the wolf
    grass grows around corpses
    wolf can eat sheep
    sheep can eat grass
    sheep can reproduce
    wolf can reproduce
    wounded entities move slower
    the older the grass the larger it is


    neural network

    allow entity  to pick their vision range
    different models for each entity instance



changes:
	input changes:
	ADD self.X AND self.Y TO INPUTS
	change input to cnn
		the cnn may be a cut out square around the entity. This reduces amount of input data, removes the need to pass entity's position
	change inputs to vectors
		will require changing outputs to vectors, small neural network may be unable tolearn mapping 2,3 -> [1,0, ... 0]
	more inputs in general
	use coding in one-layer network to pass chunks of a screen
		similiar to idea of cnn but more compact data with less precision. The previous option is preffered


	output changes:
	change output to 2 coordinates + speed:
		if vectors are inputed, should be easier to learn to go in some direction

	general changes:
	make model one layered to increase stability
	shrink enviroment, so that each decision has more impact


	optimizations:
	test only on sheep
		will swap to full simulation later

	batch training
	figure out wtf is going on in there, how q values are connected

	use dual models with freezing - more stable, hard to do


	Trials/tpyes:
	1. add x and y to inputs - omited
	2. create ml framework	- done

	3. change input to cnn
		- binning?
		- spilling?
	4. change output to 2 coordinates + speed - done
	5. add more parameters to inputs. - omited
	6. rework  learning
	7. batch training

	showcase ideas:
		- compare some metrics between random, manual, and learned
		- put different combinations of them in the same enviroment
		- show weight aggregates on image




	todo:
			connect the model to the simulation - done
			try making it learn
			a big rewrite - done
			change sizes - done
			pick final parameters for sight - done
			benchmark and try to optimize
			improve reward system
			upgrade reward view
			maybe convolution - didn't work


		nope:
			batch processing
			dqn?
			statistics


		create self-made model

		create a simpler enviroment
			update rewards
