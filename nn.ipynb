{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from timer import Timer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxFloat16 = np.finfo(np.float16).max\n",
    "neuronMax = 1\n",
    "neuronMin = -1\n",
    "neuronDtype = np.float32\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    @staticmethod\n",
    "    def sigmoid(x, derivative=False):\n",
    "        if derivative:\n",
    "            return x * (1 - x)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def relu(x, derivative=False):\n",
    "        if derivative:\n",
    "            return 1.0 * (x > 0)\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def leakyRelu(x, derivative=False):\n",
    "        if derivative:\n",
    "            return 1.0 * (x > 0) + 0.01 * (x <= 0)\n",
    "        return np.maximum(0.01 * x, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def absolute(x, derivative=False):\n",
    "        if derivative:\n",
    "            return 1 if x > 0 else -1\n",
    "        return np.abs(x)\n",
    "\n",
    "\n",
    "    # @staticmethod\n",
    "    # def softmax(x):\n",
    "    #     exps = np.exp(x - np.max(x))\n",
    "    #     return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def softmaxDerivative(x):\n",
    "    #     return x * (1 - x)\n",
    "    @staticmethod\n",
    "    def mseLoss(errorVector, derivative=False):\n",
    "        if derivative:\n",
    "            return errorVector\n",
    "        return np.mean(np.square(errorVector))*0.5\n",
    "\n",
    "    def __init__(self, layerSizes, activationFunctions):\n",
    "        self.layerSizes = layerSizes\n",
    "        self.activationFunctions = activationFunctions\n",
    "        self.layers = [\n",
    "            np.random.uniform(low=neuronMin, high=neuronMax, size=layerSizes[i]).astype(neuronDtype)\n",
    "            for i in range(len(layerSizes))\n",
    "        ]\n",
    "        self.weights = [\n",
    "            np.random.uniform(\n",
    "                low=neuronMin, high=neuronMax, size=layerSizes[i] * layerSizes[i + 1]\n",
    "            ).astype(neuronDtype).reshape(layerSizes[i], layerSizes[i + 1])\n",
    "            for i in range(len(layerSizes) - 1)\n",
    "        ]\n",
    "        self.biases = [\n",
    "            np.random.uniform(low=neuronMin, high=neuronMax, size=layerSizes[i + 1]).astype(\n",
    "                neuronDtype\n",
    "            )\n",
    "            for i in range(len(layerSizes) - 1)\n",
    "        ]\n",
    "\n",
    "    def loadInput(self, input):\n",
    "        self.layers[0] = input.astype(neuronDtype)\n",
    "\n",
    "    def readOutput(self):\n",
    "        return self.layers[-1]\n",
    "\n",
    "    def forward(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.layers[i + 1] = self.activationFunctions[i](\n",
    "                np.dot(self.layers[i], self.weights[i]) + self.biases[i]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "    def backpropagation(self, target, learning_rate, lossFunction):\n",
    "        output_error = lossFunction(target - self.layers[-1], derivative=True)\n",
    "\n",
    "        for i in range(len(self.layers) - 2, -1, -1):\n",
    "            # Calculate the derivative of the activation function\n",
    "            derivative = self.activationFunctions[i](self.layers[i + 1], derivative=True)\n",
    "\n",
    "            # Calculate the error of the current layer\n",
    "            layer_error = np.dot(output_error * derivative, self.weights[i].T) * learning_rate\n",
    "\n",
    "            # Calculate the adjustments for the weights and biases\n",
    "            weight_adjustments = np.outer(self.layers[i], output_error)\n",
    "            bias_adjustments = output_error\n",
    "\n",
    "            # Update the weights and biases\n",
    "            self.weights[i] += weight_adjustments * learning_rate\n",
    "            self.biases[i] += bias_adjustments * learning_rate\n",
    "\n",
    "            # Set the output error for the next iteration\n",
    "            # np.normalize(layer_error)\n",
    "            output_error = layer_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = NeuralNetwork([5_000, 40, 40, 3], [NeuralNetwork.leakyRelu, NeuralNetwork.leakyRelu, NeuralNetwork.leakyRelu])\n",
    "nnTimer = Timer(precision=3)\n",
    "target = np.array([2, 3, 4])\n",
    "input = np.random.uniform(low = 0, high = 1, size = 5_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9579115  -0.3506986  -0.81804395]\n"
     ]
    }
   ],
   "source": [
    "x.loadInput(input)\n",
    "x.forward()\n",
    "print(x.readOutput())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9579115  -0.3506986  -0.81804395] 8.350965315657668\n",
      "[-1.9357934  -0.33197355 -0.79111886] 8.257889562484186\n",
      "[-1.9137983  -0.31335318 -0.76434386] 8.165849846925278\n",
      "[-1.8919265  -0.29483652 -0.7377187 ] 8.074836381013988\n",
      "[-1.8701768  -0.27642354 -0.7112425 ] 7.984837584223951\n",
      "[-1.8485489  -0.25811362 -0.684914  ] 7.895842008525537\n",
      "[-1.8270413  -0.23990597 -0.65873283] 7.8078378580361365\n",
      "[-1.805654   -0.22180009 -0.63269776] 7.72081451635016\n",
      "[-1.7843868  -0.2037951  -0.60680825] 7.634761398037409\n",
      "[-1.7632381  -0.18589105 -0.5810636 ] 7.549667753205419\n",
      "[-1.7422076  -0.16808695 -0.5554626 ] 7.46552207585066\n",
      "[-1.7212945  -0.15038238 -0.5300049 ] 7.382314442245103\n",
      "[-1.7004985  -0.13277668 -0.50468946] 7.300034277210673\n",
      "[-1.6798183  -0.11526941 -0.47951534] 7.218670619613818\n",
      "[-1.6592538  -0.09786015 -0.45448193] 7.138214233954969\n",
      "[-1.6388044  -0.08054788 -0.42958838] 7.058654363605034\n",
      "[-1.618469  -0.0633324 -0.4048339] 6.979980850515919\n",
      "[-1.5982478  -0.04621321 -0.38021794] 6.902185180572374\n",
      "[-1.5781393  -0.02918974 -0.35573944] 6.825256245378799\n",
      "[-1.5581428 -0.0122613 -0.3313976] 6.7491838808979425\n",
      "[-1.5382584   0.45723855 -0.30719203] 6.256135278312958\n",
      "[-1.5184854  1.8782368 -0.2831214] 5.330536904911656\n",
      "[-1.4988223   2.5051382  -0.25918555] 5.104551253371997\n",
      "[-1.4792696   2.781682   -0.23538308] 5.015241613145461\n",
      "[-1.4598261   2.9036877  -0.21171428] 4.9530349964188884\n",
      "[-1.4404913   2.9575083  -0.18817756] 4.896602882561076\n",
      "[-1.4212642   2.9812381  -0.16477232] 4.8417881651099455\n",
      "[-1.4021446   2.9917326  -0.14149784] 4.787776703220474\n",
      "[-1.3831323   2.9963484  -0.11835331] 4.734405296494808\n",
      "[-1.3642257   2.998395   -0.09533838] 4.681635650412016\n",
      "[-1.3454248   2.999282   -0.07245145] 4.629454704703547\n",
      "[-1.3267295   2.9996939  -0.04969332] 4.577857580900932\n",
      "[-1.3081381   2.999858   -0.02706198] 4.526834347287639\n",
      "[-1.289651    2.9999456  -0.00455691] 4.476380001415738\n",
      "[-1.271267   2.999961   1.7822362] 2.6032773911645157\n",
      "[-1.2529857  2.9999895  3.021608 ] 1.9231944583091451\n",
      "[-1.2348068  2.9999895  3.5683794] 1.7750452031578732\n",
      "[-1.2167292  2.9999895  3.809558 ] 1.7306024505455753\n",
      "[-1.1987531  2.9999971  3.9159985] 1.7065129620218709\n",
      "[-1.1808769  2.9999971  3.9629354] 1.686558553799048\n",
      "[-1.1631007  2.9999971  3.9836583] 1.6675788686857989\n",
      "[-1.145424   2.9999971  3.9928162] 1.6489572998794724\n",
      "[-1.127846   2.9999971  3.9968157] 1.6305717926234233\n",
      "[-1.1103663  2.9999971  3.9985757] 1.612396804228941\n",
      "[-1.0929844  2.9999971  3.9993558] 1.5944255247275596\n",
      "[-1.0756994  2.9999971  3.999714 ] 1.5766545299819867\n",
      "[-1.0585111  2.9999971  3.9998865] 1.559081732321206\n",
      "[-1.0414189  2.9999971  3.9999576] 1.5417048313460502\n",
      "[-1.0244222  2.9999971  3.9999733] 1.5245215759061541\n",
      "[-1.0075206  2.9999971  3.9999738] 1.5075299830274413\n",
      "[-0.9907134  2.9999971  3.9999743] 1.4907277910775896\n",
      "[-0.974      2.9999971  3.9999824] 1.4741126440300907\n",
      "[-0.95738    2.9999971  3.9999828] 1.4576827409395186\n",
      "[-0.9408529  2.9999971  3.9999833] 1.4414359441503184\n",
      "[-0.92441803  2.9999971   3.9999833 ] 1.4253701378606543\n",
      "[-0.90807533  2.9999971   3.9999838 ] 1.4094836900982652\n",
      "[-0.8918237  2.9999971  3.9999838] 1.3937740607116027\n",
      "[-0.875663   2.9999971  3.9999843] 1.378239598161434\n",
      "[-0.85959244  2.9999971   3.9999847 ] 1.3628781517074156\n",
      "[-0.8436119  2.9999971  3.9999924] 1.3476881025592562\n",
      "[-0.82772046  2.9999971   3.9999928 ] 1.3326671697481114\n",
      "[-0.8119181  2.9999971  3.9999928] 1.3178138813106421\n",
      "[-0.79620373  2.9999971   3.9999928 ] 1.303125885608895\n",
      "[-0.78057724  2.9999971   3.9999933 ] 1.2886016334772143\n",
      "[-0.7650384  2.9999971  3.9999933] 1.2742395322718896\n",
      "[-0.749586   2.9999971  3.9999933] 1.260037182535979\n",
      "[-0.7342203  2.9999971  3.9999938] 1.2459934651445466\n",
      "[-0.7189403  2.9999971  3.9999938] 1.232106075147452\n",
      "[-0.7037458  2.9999971  3.9999938] 1.2183735426265045\n",
      "[-0.6886362  2.9999971  3.9999943] 1.2047940880916623\n",
      "[-0.67361104  2.9999971   3.9999943 ] 1.1913660032275313\n",
      "[-0.6586697  2.9999971  3.9999943] 1.1780874379599122\n",
      "[-0.643812   2.9999971  3.9999948] 1.164956982558887\n",
      "[-0.6290373  2.9999971  3.9999948] 1.1519728722027012\n",
      "[-0.6143452  2.9999971  3.9999948] 1.1391334646205589\n",
      "[-0.5997351  2.9999971  3.9999952] 1.1264370820718697\n",
      "[-0.5852065  2.9999971  3.9999952] 1.1138821153878855\n",
      "[-0.5707595  2.9999971  3.9999952] 1.1014673799202945\n",
      "[-0.5563928  2.9999971  3.9999957] 1.0891906818500299\n",
      "[-0.5421066  2.9999971  3.9999957] 1.0770510183788626\n",
      "[-0.5279004  2.9999971  3.9999957] 1.065046736851756\n",
      "[-0.5137734  2.9999971  3.9999957] 1.053176102436766\n",
      "[-0.49972525  2.9999971   3.9999957 ] 1.0414377229103986\n",
      "[-0.4857558  2.9999971  3.9999957] 1.029830317205061\n",
      "[-0.47186446  2.9999971   3.9999957 ] 1.0183523196708109\n",
      "[-0.45805046  2.9999971   3.9999957 ] 1.00700201034685\n",
      "[-0.44431385  2.9999971   4.000011  ] 0.9957783694804466\n",
      "[-0.43065402  2.9999971   3.9999876 ] 0.9846798268022071\n",
      "[-0.4170704  2.9999971  4.000011 ] 0.97370487741883\n",
      "[-0.40356284  2.9999971   3.9999876 ] 0.9628523907093113\n",
      "[-0.3901309  2.9999971  4.000011 ] 0.9521209590242482\n",
      "[-0.37677372  2.9999971   3.9999876 ] 0.9415088820946972\n",
      "[-0.36349136  2.9999971   4.000011  ] 0.9310152319629269\n",
      "[-0.350283   2.9999971  3.9999876] 0.9206383609409831\n",
      "[-0.3371488  2.9999971  4.000011 ] 0.9103774076864232\n",
      "[-0.32408786  2.9999971   3.9999876 ] 0.900230728799149\n",
      "[-0.3110998  2.9999971  4.000011 ] 0.8901970456790192\n",
      "[-0.29818437  2.9999971   3.9999876 ] 0.8802752293081825\n",
      "[-0.28534132  2.9999971   4.000011  ] 0.8704641600163546\n",
      "[-0.27256972  2.9999971   3.9999876 ] 0.8607621856893962\n",
      "[-0.25986964  2.9999971   4.000011  ] 0.8511684612997789\n",
      "[-0.24724044  2.9999971   3.9999876 ] 0.8416815985160936\n",
      "[-0.23468211  2.9999971   4.000011  ] 0.8323006909979352\n",
      "[-0.2221939  2.9999971  3.9999876] 0.8230242858343081\n",
      "[-0.20977527  2.9999971   4.000011  ] 0.8138511232919688\n",
      "[-0.19742616  2.9999971   3.9999876 ] 0.8047802846268128\n",
      "[-0.18514596  2.9999971   4.000011  ] 0.7958104772317297\n",
      "[-0.17293453  2.9999971   3.9999876 ] 0.7869407468732182\n",
      "[-0.16079126  2.9999971   4.000011  ] 0.7781698137196079\n",
      "[-0.14871573  2.9999971   3.9999876 ] 0.7694965512952668\n",
      "[-0.13670786  2.9999971   4.000011  ] 0.7609200778945567\n",
      "[-0.12476695  2.9999971   3.9999876 ] 0.7524390957152628\n",
      "[-0.1128929  2.9999971  4.000011 ] 0.7440527316382274\n",
      "[-0.10108522  2.9999971   3.9999876 ] 0.7357598525921807\n",
      "[-0.08934349  2.9999971   4.000011  ] 0.7275593686467902\n",
      "[-0.07766743  2.9999971   3.9999876 ] 0.7194503250040484\n",
      "[-0.06605639  2.9999971   4.000011  ] 0.7114315032572933\n",
      "[-0.05451049  2.9999971   3.9999876 ] 0.7035022250015329\n",
      "[-0.04302893  2.9999971   4.000011  ] 0.6956612028970312\n",
      "[-0.03161174  2.9999971   3.9999876 ] 0.6879077107769221\n",
      "[-0.02025823  2.9999971   4.000011  ] 0.680240549638539\n",
      "[-0.00896813  2.9999971   3.9999876 ] 0.6726588256689051\n",
      "[0.22587714 2.9999971  4.000011  ] 0.5245853227873728\n",
      "[1.2173405 2.9999971 3.9999876] 0.10209265684382747\n",
      "[1.6547061 2.9999971 4.000011 ] 0.019871310559137118\n",
      "[1.8476837 2.9999971 3.9999876] 0.0038667108523687452\n",
      "[1.932814  2.9999971 4.000011 ] 0.0007523264084573119\n",
      "[1.9703561 2.9999971 3.9999876] 0.00014646009473769558\n",
      "[1.9869388 2.9999971 4.000011 ] 2.843236346213492e-05\n",
      "[1.9942174 2.9999971 3.9999876] 5.573112237774088e-06\n",
      "[1.9974552 2.9999971 4.000011 ] 1.0793225844925776e-06\n",
      "[1.9988648 2.9999971 3.9999876] 2.1481819819276401e-07\n",
      "[1.9995018 2.9999971 4.000011 ] 4.1384569252992755e-08\n",
      "[1.9997774 2.9999971 3.9999876] 8.282751669715557e-09\n",
      "[1.9999071 2.9999971 4.000011 ] 1.4586992354755541e-09\n",
      "[1.9999548 2.9999971 3.9999876] 3.671919065103187e-10\n",
      "[1.999971  2.9999971 4.000011 ] 1.612671477838982e-10\n",
      "[1.9999863 2.9999971 3.9999876] 5.830476842068795e-11\n",
      "[1.9999863 2.9999971 4.000011 ] 5.273411337232877e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "[1.9999901 2.9999971 4.000011 ] 3.7727450793075455e-11\n",
      "[1.9999901 2.9999971 3.9999876] 4.329810584143464e-11\n",
      "Total time: 0.563 s\n",
      "Total calls: 200\n",
      "Average time: 0.002815 s\n"
     ]
    }
   ],
   "source": [
    "# learning_rate = 0.00001\n",
    "# for i in range(200):\n",
    "#     nnTimer.tic()\n",
    "#     x.loadInput(input)\n",
    "#     x.forward()\n",
    "#     x.backpropagation(target, learning_rate)\n",
    "#     print(x.readOutput())\n",
    "#     nnTimer.toc()\n",
    "# nnTimer.stats()\n",
    "learning_rate = 0.00001\n",
    "for i in range(200):\n",
    "    nnTimer.tic()\n",
    "    x.loadInput(input)\n",
    "    x.forward()\n",
    "    x.backpropagation(target, learning_rate, NeuralNetwork.mseLoss)\n",
    "    print(x.readOutput(), NeuralNetwork.mseLoss(target - x.readOutput()))\n",
    "    nnTimer.toc()\n",
    "nnTimer.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
